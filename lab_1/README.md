# ЛР 1 — вариант 7

## Разведочный и регрессионный анализ прочности бетона

### Задание
Построить регрессионные модели для прогнозирования компрессионной прочности бетона на основе:
- Полносвязной нейронной сети (Dense)
- Одномерной сверточной нейронной сети (1D CNN)

### Датасет
- **Файл**: V7_dataset.csv
- **Размер**: 1030 образцов (1005 после очистки)
- **Признаки**: 8 входных признаков + 1 целевой
  - cement (цемент)
  - blast_furnace_slag (доменный шлак)
  - fly_ash (летучая зола)
  - water (вода)
  - superplasticizer (суперпластификатор)
  - coarse_aggregate (крупный заполнитель)
  - fine_aggregate (мелкий заполнитель)
  - age (возраст бетона, дни)
- **Целевая переменная**: concrete_compressive_strength (прочность на сжатие, МПа)

### Результаты анализа

#### Лучшая модель
- **Архитектура**: 1D Convolutional Neural Network
- **Датасет**: original_scaled (все признаки + инженерные признаки, стандартизированные)
- **Метрики на тестовой выборке**:
  - RMSE: 5.48 МПа
  - R²: 0.891 (89.1% объясненной дисперсии)
  - MAE: 3.79 МПа

#### Оптимальные гиперпараметры (после Grid Search)
- Фильтры: 64
- Размер ядра: 5
- Dropout: 0.3
- Learning rate: 0.0005

#### Инженерные признаки
Созданы дополнительные признаки на основе предметных знаний:
1. water_cement_ratio - соотношение вода/цемент (критический параметр)
2. water_binder_ratio - соотношение вода/вяжущие материалы
3. total_aggregate - общее количество заполнителей
4. binder_content - общее содержание вяжущих материалов
5. age_squared - квадрат возраста (нелинейный эффект)
6. age_log - логарифм возраста

#### Сравнение моделей (8 конфигураций)
| Датасет | Модель | Val RMSE | Val R² |
|---------|--------|----------|--------|
| original_scaled | Conv1D | **4.86** | **0.906** |
| original_scaled | Dense | 5.12 | 0.896 |
| selected_scaled | Conv1D | 5.79 | 0.867 |
| selected_scaled | Dense | 6.19 | 0.848 |
| selected | Conv1D | 10.93 | 0.527 |
| original | Conv1D | 17.25 | -0.179 |
| original | Dense | 19.77 | -0.548 |
| selected | Dense | 25.40 | -1.554 |

### Выводы

1. **Влияние стандартизации**: критически важна для обучения нейронных сетей
   - Модели на нестандартизированных данных показали плохие результаты (отрицательный R²)
   - Стандартизация улучшила R² с -0.18 до 0.91 для Conv1D

2. **Влияние отбора признаков**: использование всех признаков оказалось лучше
   - original_scaled (14 признаков) > selected_scaled (9 признаков)
   - Val RMSE: 4.86 vs 5.79

3. **Сравнение архитектур**: 1D CNN превосходит полносвязную сеть
   - Conv1D лучше улавливает паттерны в признаковом пространстве
   - Val RMSE: 4.86 (Conv1D) vs 5.12 (Dense)

4. **Влияние Grid Search**: небольшое улучшение (+2.1% по RMSE)
   - Test RMSE до: 5.59
   - Test RMSE после: 5.48
   - Подобранные параметры: kernel_size=5, filters=64, dropout=0.3

5. **Практическая применимость**:
   - Средняя ошибка прогноза: ±3.79 МПа
   - 89% вариации прочности объясняется моделью
   - Модель подходит для практического применения в строительстве

### Структура проекта

```
lab_1/
├── V7_dataset.csv                  # Исходные данные
├── lab_1_variant_7.py              # Основной скрипт
├── venv/                           # Виртуальное окружение
├── lab_1_artifacts/                # Результаты анализа
│   ├── results_summary.json        # Сводка метрик
│   ├── correlation_heatmap.png     # Корреляционная матрица
│   ├── scatter_plots.png           # Графики рассеяния
│   └── dist_*.png                  # Распределения признаков
└── README.md                       # Этот файл
```

### Запуск анализа

```bash
# Создать виртуальное окружение
python3 -m venv venv
source venv/bin/activate

# Установить зависимости
pip install pandas numpy matplotlib seaborn scikit-learn keras jax jaxlib

# Запустить анализ
python lab_1_variant_7.py
```

### Зависимости
- Python 3.14.2
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- keras 3 (с JAX backend)
- jax, jaxlib

### Автор
Выполнено в рамках курса "Интеллектуальный анализ данных"
