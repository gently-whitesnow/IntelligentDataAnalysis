# ЛР 2 — вариант 7

## Классификация уровней ожирения на основе привычек питания и физического состояния

### Задание
Построить модели классификации для предсказания уровней ожирения на основе:
- Полносвязной нейронной сети (Dense)
- Двунаправленной рекуррентной нейронной сети (Bidirectional GRU)

### Датасет
- **Файл**: V7_classification_lr3.csv
- **Размер**: 2111 образцов (2087 после очистки дубликатов)
- **Признаки**: 16 входных признаков + 1 целевой
  - Gender (пол)
  - Age (возраст)
  - Height (рост)
  - Weight (вес)
  - family_history_with_overweight (семейная история избыточного веса)
  - FAVC (частое употребление высококалорийной пищи)
  - FCVC (частота употребления овощей)
  - NCP (количество основных приемов пищи)
  - CAEC (употребление пищи между приемами)
  - SMOKE (курение)
  - CH2O (потребление воды)
  - SCC (мониторинг калорий)
  - FAF (частота физической активности)
  - TUE (время использования технологий)
  - CALC (употребление алкоголя)
  - MTRANS (средство передвижения)
- **Целевая переменная**: NObeyesdad (уровень ожирения, 7 классов)
  - Insufficient_Weight (недостаточный вес)
  - Normal_Weight (нормальный вес)
  - Overweight_Level_I (избыточный вес I)
  - Overweight_Level_II (избыточный вес II)
  - Obesity_Type_I (ожирение типа I)
  - Obesity_Type_II (ожирение типа II)
  - Obesity_Type_III (ожирение типа III)

### Результаты анализа

#### Лучшая модель
- **Архитектура**: Bidirectional GRU (двунаправленная рекуррентная сеть)
- **Датасет**: selected_scaled (21 отобранных признаков, Min-Max масштабирование)
- **Метрики на тестовой выборке (после Random Search)**:
  - Accuracy: 0.9745 (97.45%)
  - Balanced Accuracy: 0.9732 (97.32%)
  - F1-score (macro): 0.9729
  - F1-score (weighted): 0.9743

#### Оптимальные гиперпараметры (после Random Search)
- GRU units (1-й слой): 64
- GRU units (2-й слой): 64
- Dropout: 0.4
- Learning rate: 0.001

#### Инженерные признаки
Созданы дополнительные признаки на основе предметных знаний:
1. **BMI** - индекс массы тела (вес / рост²) - критический показатель ожирения
2. **age_weight_interaction** - взаимодействие возраста и веса
3. **height_weight_ratio** - соотношение роста к весу
4. **water_activity_ratio** - соотношение потребления воды и физической активности
5. **meal_frequency_score** - оценка частоты питания

#### Отбор признаков
На основе Mutual Information (взаимной информации) отобраны топ-70% признаков:
- **Топ-5 признаков**:
  1. BMI (MI: 1.827)
  2. height_weight_ratio (MI: 1.430)
  3. Weight (MI: 1.251)
  4. age_weight_interaction (MI: 0.882)
  5. Age (MI: 0.589)

#### Сравнение моделей (8 конфигураций)
| Датасет | Модель | Val Balanced Acc | Val F1 |
|---------|--------|------------------|--------|
| selected_scaled | BiGRU | **0.9766** | **0.9764** |
| original | BiGRU | 0.9739 | 0.9739 |
| selected | BiGRU | 0.9702 | 0.9698 |
| selected_scaled | Dense | 0.9559 | 0.9559 |
| original_scaled | Dense | 0.9348 | 0.9348 |
| original_scaled | BiGRU | 0.9314 | 0.9302 |
| original | Dense | 0.1429 | 0.0345 |
| selected | Dense | 0.1202 | 0.0485 |

### Выводы

1. **Влияние Min-Max масштабирования**: критически важно для обучения нейронных сетей
   - Dense модели на немасштабированных данных показали крайне плохие результаты (Balanced Acc: ~14%)
   - Масштабирование улучшило качество с 14% до 95%+ для Dense моделей

2. **Влияние отбора признаков**: отобранные признаки показали лучший результат
   - selected_scaled (21 признак) > original_scaled (31 признак)
   - Val Balanced Acc: 0.9766 vs 0.9314 для BiGRU
   - Отбор признаков уменьшил переобучение и повысил обобщающую способность

3. **Сравнение архитектур**: Bidirectional GRU значительно превосходит Dense
   - BiGRU лучше улавливает последовательные зависимости в признаках
   - Val Balanced Acc: 0.9766 (BiGRU) vs 0.9559 (Dense)
   - BiGRU показала более стабильные результаты на всех конфигурациях датасетов

4. **Влияние Random Search**: небольшое, но стабильное улучшение
   - Test Accuracy: +1.66% (0.9586 → 0.9745)
   - Test Balanced Accuracy: +1.69% (0.9570 → 0.9732)
   - Test F1-score: +1.76% (0.9560 → 0.9729)
   - Оптимальная конфигурация: BiGRU(64, 64) с dropout=0.4

5. **Анализ качества по классам** (после оптимизации):
   - Obesity_Type_III: F1=1.00 (идеальная классификация)
   - Obesity_Type_II: F1=0.99
   - Obesity_Type_I: F1=0.99
   - Insufficient_Weight: F1=0.98
   - Overweight_Level_II: F1=0.97
   - Normal_Weight: F1=0.95
   - Overweight_Level_I: F1=0.94
   - Все классы показывают отличное качество (F1 > 0.94)

6. **Практическая применимость**:
   - Модель показывает отличное качество классификации (97.45% точности)
   - Balanced Accuracy (97.32%) подтверждает хорошую работу на всех классах
   - Модель может использоваться для медицинской диагностики и предсказания уровня ожирения
   - Наиболее важные признаки: BMI, вес, рост, возраст - легко измеримы

7. **Эффективность Random Search**:
   - Использовано 9 случайных комбинаций вместо 81 (полный grid search)
   - Ускорение в ~9 раз при сохранении качества результата
   - Random Search эффективен для подбора гиперпараметров нейросетей

### Структура проекта

```
lab_2/
├── V7_classification_lr3.csv       # Исходные данные
├── lab_2_variant_7.py              # Основной скрипт
├── venv/                           # Виртуальное окружение
├── lab_2_artifacts/                # Результаты анализа
│   ├── results_summary.json        # Сводка метрик
│   ├── correlation_heatmap.png     # Корреляционная матрица
│   ├── confusion_matrix_best.png   # Матрица ошибок (до оптимизации)
│   ├── confusion_matrix_final.png  # Матрица ошибок (после Random Search)
│   ├── target_distribution.png     # Распределение целевой переменной
│   └── dist_*.png                  # Распределения признаков (17 графиков)
└── README.md                       # Этот файл
```

### Запуск анализа

```bash
# Создать виртуальное окружение
python3 -m venv venv
source venv/bin/activate

# Установить зависимости
pip install pandas numpy matplotlib seaborn scikit-learn keras jax jaxlib

# Запустить анализ
python lab_2_variant_7.py
```

### Зависимости
- Python 3.x
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- keras 3 (с JAX backend)
- jax, jaxlib

### Особенности реализации

1. **Преобразование данных**: Min-Max масштабирование для нормализации признаков в диапазон [0, 1]
2. **Кодирование признаков**:
   - Label Encoding для бинарных признаков (Gender, FAVC, SMOKE и др.)
   - One-Hot Encoding для мультикатегориальных признаков (CAEC, CALC, MTRANS)
3. **Разбиение данных**: стратифицированное 70/15/15 (train/val/test)
4. **Early Stopping**: остановка при отсутствии улучшения val_loss в течение 20 эпох
5. **ReduceLROnPlateau**: динамическое уменьшение learning rate при застревании
6. **Random Search**: эффективный подбор гиперпараметров (9 случайных комбинаций)



